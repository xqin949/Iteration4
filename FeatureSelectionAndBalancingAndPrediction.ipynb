{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('test1').getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data of air quality/finaldataset.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+----+-----+-----+----+----+-----+-------+-------+---+----------+-------------------+---------+\n",
      "|                Date| PM25|  NO| NO2|  NOx|  NH3|  CO| SO2|   O3|Benzene|Toluene|AQI|AQI_Bucket|ChangeStrategyOrNot|CityIndex|\n",
      "+--------------------+-----+----+----+-----+-----+----+----+-----+-------+-------+---+----------+-------------------+---------+\n",
      "|2020-03-12 00:00:...|31.21| 7.2|1.27|10.65|25.63|0.56|4.22| 2.81|   0.01|   0.08| 52|         2|                  0|       15|\n",
      "|2020-03-13 00:00:...|38.39|7.19|0.91|10.37|29.16|0.57|4.46| 0.18|    0.0|    0.0| 60|         2|                  0|       15|\n",
      "|2020-03-14 00:00:...|43.23|7.14|1.07|10.48|28.95|0.57|4.53| 0.41|    0.0|    0.0| 62|         2|                  0|       15|\n",
      "|2020-03-15 00:00:...|33.82|7.09|0.36| 9.73|28.41|0.48|4.63|  0.3|    0.0|    0.0| 70|         2|                  0|       15|\n",
      "|2020-03-16 00:00:...|27.14|5.63|2.32| 8.09|23.98| 0.5|4.71|13.02|   0.13|   0.68| 54|         2|                  0|       15|\n",
      "|2020-03-17 00:00:...|27.32|3.07|2.14| 3.41|24.57|0.48|4.84| 6.03|   0.25|   1.34| 40|         1|                  0|       15|\n",
      "|2020-03-18 00:00:...|31.76| 3.0|1.48| 5.24|23.42|0.47|5.04| 8.76|   0.24|   1.19| 51|         2|                  0|       15|\n",
      "|2020-03-19 00:00:...| 43.8|2.97|1.31| 4.97|23.41|0.48| 5.3| 9.96|   0.26|   1.11| 63|         2|                  0|       15|\n",
      "|2020-03-20 00:00:...|35.48|3.01|0.83| 4.64|24.85|0.49|5.32| 6.43|   0.27|   1.15| 69|         2|                  0|       15|\n",
      "|2020-03-21 00:00:...|51.27|3.01|0.88| 4.62|24.44|0.49|5.63| 8.62|  49.66|  50.11| 70|         2|                  0|       15|\n",
      "|2020-03-22 00:00:...|33.24|2.93|0.13| 3.65|18.55|0.37|5.41| 5.64|  13.07|  13.69| 71|         2|                  0|       15|\n",
      "|2020-03-23 00:00:...|35.34|2.98|0.16| 3.71|20.24|0.32|5.63| 5.73|  62.93|  62.45| 53|         2|                  0|       15|\n",
      "|2020-03-24 00:00:...|47.34|2.96|0.14| 3.66|20.21|0.37|6.17| 5.59|   0.33|   0.33| 66|         2|                  0|       15|\n",
      "|2020-03-25 00:00:...|53.64|2.96|0.17| 3.77|25.43|0.44|6.75| 6.44|   0.23|   0.84| 92|         2|                  0|       15|\n",
      "|2020-03-26 00:00:...| 54.9|2.96|0.13| 3.69|25.48|0.42| 6.8| 5.87|   0.25|   0.92| 89|         2|                  0|       15|\n",
      "|2020-03-27 00:00:...|44.64|2.94|0.11| 3.59|28.26| 0.4|7.34| 6.42|   0.22|   0.82| 82|         2|                  0|       15|\n",
      "|2020-03-28 00:00:...|51.33|2.92|0.35| 3.89|29.89|0.44|7.69| 8.76|   0.23|   0.66| 71|         2|                  0|       15|\n",
      "|2020-03-29 00:00:...|34.54|2.93|0.13| 3.64|28.47|0.36| 7.8| 7.99|   0.19|    0.6| 81|         2|                  0|       15|\n",
      "|2020-03-30 00:00:...|39.47|2.93|0.24| 3.79|29.05|0.42|7.67|  7.4|   0.19|   0.73| 60|         2|                  0|       15|\n",
      "|2020-03-31 00:00:...|27.27|2.95|0.25|  3.8|30.99| 0.4| 7.9| 6.74|   0.18|    0.8| 51|         2|                  0|       15|\n",
      "+--------------------+-----+----+----+-----+-----+----+----+-----+-------+-------+---+----------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- PM25: double (nullable = true)\n",
      " |-- NO: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- NOx: double (nullable = true)\n",
      " |-- NH3: double (nullable = true)\n",
      " |-- CO: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- Benzene: double (nullable = true)\n",
      " |-- Toluene: double (nullable = true)\n",
      " |-- AQI: integer (nullable = true)\n",
      " |-- AQI_Bucket: integer (nullable = true)\n",
      " |-- ChangeStrategyOrNot: integer (nullable = true)\n",
      " |-- CityIndex: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()\n",
    "df=df.drop(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+-----+\n",
      "|features                                                             |label|\n",
      "+---------------------------------------------------------------------+-----+\n",
      "|[31.21,7.2,1.27,10.65,25.63,0.56,4.22,2.81,0.01,0.08,52.0,2.0,15.0]  |0.0  |\n",
      "|[38.39,7.19,0.91,10.37,29.16,0.57,4.46,0.18,0.0,0.0,60.0,2.0,15.0]   |0.0  |\n",
      "|[43.23,7.14,1.07,10.48,28.95,0.57,4.53,0.41,0.0,0.0,62.0,2.0,15.0]   |0.0  |\n",
      "|[33.82,7.09,0.36,9.73,28.41,0.48,4.63,0.3,0.0,0.0,70.0,2.0,15.0]     |0.0  |\n",
      "|[27.14,5.63,2.32,8.09,23.98,0.5,4.71,13.02,0.13,0.68,54.0,2.0,15.0]  |0.0  |\n",
      "|[27.32,3.07,2.14,3.41,24.57,0.48,4.84,6.03,0.25,1.34,40.0,1.0,15.0]  |0.0  |\n",
      "|[31.76,3.0,1.48,5.24,23.42,0.47,5.04,8.76,0.24,1.19,51.0,2.0,15.0]   |0.0  |\n",
      "|[43.8,2.97,1.31,4.97,23.41,0.48,5.3,9.96,0.26,1.11,63.0,2.0,15.0]    |0.0  |\n",
      "|[35.48,3.01,0.83,4.64,24.85,0.49,5.32,6.43,0.27,1.15,69.0,2.0,15.0]  |0.0  |\n",
      "|[51.27,3.01,0.88,4.62,24.44,0.49,5.63,8.62,49.66,50.11,70.0,2.0,15.0]|0.0  |\n",
      "|[33.24,2.93,0.13,3.65,18.55,0.37,5.41,5.64,13.07,13.69,71.0,2.0,15.0]|0.0  |\n",
      "|[35.34,2.98,0.16,3.71,20.24,0.32,5.63,5.73,62.93,62.45,53.0,2.0,15.0]|0.0  |\n",
      "|[47.34,2.96,0.14,3.66,20.21,0.37,6.17,5.59,0.33,0.33,66.0,2.0,15.0]  |0.0  |\n",
      "|[53.64,2.96,0.17,3.77,25.43,0.44,6.75,6.44,0.23,0.84,92.0,2.0,15.0]  |0.0  |\n",
      "|[54.9,2.96,0.13,3.69,25.48,0.42,6.8,5.87,0.25,0.92,89.0,2.0,15.0]    |0.0  |\n",
      "|[44.64,2.94,0.11,3.59,28.26,0.4,7.34,6.42,0.22,0.82,82.0,2.0,15.0]   |0.0  |\n",
      "|[51.33,2.92,0.35,3.89,29.89,0.44,7.69,8.76,0.23,0.66,71.0,2.0,15.0]  |0.0  |\n",
      "|[34.54,2.93,0.13,3.64,28.47,0.36,7.8,7.99,0.19,0.6,81.0,2.0,15.0]    |0.0  |\n",
      "|[39.47,2.93,0.24,3.79,29.05,0.42,7.67,7.4,0.19,0.73,60.0,2.0,15.0]   |0.0  |\n",
      "|[27.27,2.95,0.25,3.8,30.99,0.4,7.9,6.74,0.18,0.8,51.0,2.0,15.0]      |0.0  |\n",
      "+---------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "formula = RFormula(\n",
    "    formula = 'ChangeStrategyOrNot ~ .',\n",
    "    featuresCol = 'features',\n",
    "    labelCol = 'label'\n",
    "    )\n",
    "\n",
    "resultofvec = formula.fit(df).transform(df)\n",
    "dfvectorformat = resultofvec.select('features','label')\n",
    "dfvectorformat.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(numTrees = int(9), maxDepth = int(5), labelCol = 'label', seed = 11)\n",
    "rfmodel = model.fit(dfvectorformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PM25', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'AQI', 'AQI_Bucket', 'CityIndex']\n"
     ]
    }
   ],
   "source": [
    "importance = rfmodel.featureImportances\n",
    "column_list = df.columns\n",
    "column_list.remove(\"ChangeStrategyOrNot\")\n",
    "print(column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O3': 0.0012312572791757417, 'CO': 0.00015199902047995084, 'NOx': 0.26403267447796913, 'Benzene': 0.0, 'Toluene': 0.0, 'NO2': 0.0, 'CityIndex': 0.050996252281869776, 'SO2': 0.006771384045941805, 'NO': 0.0001492801460635482, 'PM25': 0.08825140064994251, 'NH3': 0.0020205165017734314, 'AQI': 0.04108780924144026, 'AQI_Bucket': 0.5453074263553438}\n"
     ]
    }
   ],
   "source": [
    "importancesList = [float(col) for col in importance ]\n",
    "\n",
    "final = dict(zip(column_list, importancesList))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Project data\n",
    "from pyspark.sql.functions import col, explode, array, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4654 2020\n"
     ]
    }
   ],
   "source": [
    "minor_df = dfvectorformat.filter(col(\"label\") == 1)\n",
    "major_df = dfvectorformat.filter(col(\"label\") == 0)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(major_df.count(),minor_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[31.21,7.2,1.27,1...|  0.0|\n",
      "|[38.39,7.19,0.91,...|  0.0|\n",
      "|[43.23,7.14,1.07,...|  0.0|\n",
      "|[33.82,7.09,0.36,...|  0.0|\n",
      "|[27.14,5.63,2.32,...|  0.0|\n",
      "|[27.32,3.07,2.14,...|  0.0|\n",
      "|[31.76,3.0,1.48,5...|  0.0|\n",
      "|[43.8,2.97,1.31,4...|  0.0|\n",
      "|[35.48,3.01,0.83,...|  0.0|\n",
      "|[51.27,3.01,0.88,...|  0.0|\n",
      "|[33.24,2.93,0.13,...|  0.0|\n",
      "|[35.34,2.98,0.16,...|  0.0|\n",
      "|[47.34,2.96,0.14,...|  0.0|\n",
      "|[53.64,2.96,0.17,...|  0.0|\n",
      "|[54.9,2.96,0.13,3...|  0.0|\n",
      "|[44.64,2.94,0.11,...|  0.0|\n",
      "|[51.33,2.92,0.35,...|  0.0|\n",
      "|[34.54,2.93,0.13,...|  0.0|\n",
      "|[39.47,2.93,0.24,...|  0.0|\n",
      "|[27.27,2.95,0.25,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = range(ratio)\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "combined_df = major_df.unionAll(oversampled_df)\n",
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4654 4040\n"
     ]
    }
   ],
   "source": [
    "minor_df = combined_df.filter(col(\"label\") == 1)\n",
    "major_df = combined_df.filter(col(\"label\") == 0)\n",
    "\n",
    "print(major_df.count(),minor_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PM25: double (nullable = true)\n",
      " |-- NO: double (nullable = true)\n",
      " |-- NO2: double (nullable = true)\n",
      " |-- NOx: double (nullable = true)\n",
      " |-- NH3: double (nullable = true)\n",
      " |-- CO: double (nullable = true)\n",
      " |-- SO2: double (nullable = true)\n",
      " |-- O3: double (nullable = true)\n",
      " |-- Benzene: double (nullable = true)\n",
      " |-- Toluene: double (nullable = true)\n",
      " |-- ChangeStrategyOrNot: integer (nullable = true)\n",
      " |-- CityIndex: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finaldf = df.drop(\"AQI\", 'AQI_Bucket')\n",
    "finaldf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+-----+\n",
      "|features                                                    |label|\n",
      "+------------------------------------------------------------+-----+\n",
      "|[31.21,7.2,1.27,10.65,25.63,0.56,4.22,2.81,0.01,0.08,15.0]  |0.0  |\n",
      "|[38.39,7.19,0.91,10.37,29.16,0.57,4.46,0.18,0.0,0.0,15.0]   |0.0  |\n",
      "|[43.23,7.14,1.07,10.48,28.95,0.57,4.53,0.41,0.0,0.0,15.0]   |0.0  |\n",
      "|[33.82,7.09,0.36,9.73,28.41,0.48,4.63,0.3,0.0,0.0,15.0]     |0.0  |\n",
      "|[27.14,5.63,2.32,8.09,23.98,0.5,4.71,13.02,0.13,0.68,15.0]  |0.0  |\n",
      "|[27.32,3.07,2.14,3.41,24.57,0.48,4.84,6.03,0.25,1.34,15.0]  |0.0  |\n",
      "|[31.76,3.0,1.48,5.24,23.42,0.47,5.04,8.76,0.24,1.19,15.0]   |0.0  |\n",
      "|[43.8,2.97,1.31,4.97,23.41,0.48,5.3,9.96,0.26,1.11,15.0]    |0.0  |\n",
      "|[35.48,3.01,0.83,4.64,24.85,0.49,5.32,6.43,0.27,1.15,15.0]  |0.0  |\n",
      "|[51.27,3.01,0.88,4.62,24.44,0.49,5.63,8.62,49.66,50.11,15.0]|0.0  |\n",
      "|[33.24,2.93,0.13,3.65,18.55,0.37,5.41,5.64,13.07,13.69,15.0]|0.0  |\n",
      "|[35.34,2.98,0.16,3.71,20.24,0.32,5.63,5.73,62.93,62.45,15.0]|0.0  |\n",
      "|[47.34,2.96,0.14,3.66,20.21,0.37,6.17,5.59,0.33,0.33,15.0]  |0.0  |\n",
      "|[53.64,2.96,0.17,3.77,25.43,0.44,6.75,6.44,0.23,0.84,15.0]  |0.0  |\n",
      "|[54.9,2.96,0.13,3.69,25.48,0.42,6.8,5.87,0.25,0.92,15.0]    |0.0  |\n",
      "|[44.64,2.94,0.11,3.59,28.26,0.4,7.34,6.42,0.22,0.82,15.0]   |0.0  |\n",
      "|[51.33,2.92,0.35,3.89,29.89,0.44,7.69,8.76,0.23,0.66,15.0]  |0.0  |\n",
      "|[34.54,2.93,0.13,3.64,28.47,0.36,7.8,7.99,0.19,0.6,15.0]    |0.0  |\n",
      "|[39.47,2.93,0.24,3.79,29.05,0.42,7.67,7.4,0.19,0.73,15.0]   |0.0  |\n",
      "|[27.27,2.95,0.25,3.8,30.99,0.4,7.9,6.74,0.18,0.8,15.0]      |0.0  |\n",
      "+------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "f = RFormula(\n",
    "    formula = 'ChangeStrategyOrNot ~ .',\n",
    "    featuresCol = 'features',\n",
    "    labelCol = 'label'\n",
    "    )\n",
    "\n",
    "vec = f.fit(finaldf).transform(finaldf)\n",
    "df2vec = vec.select('features','label')\n",
    "df2vec.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df2vec.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3.1 decision tree\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model. \n",
    "model_dt = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "prediction_dt = model_dt.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary classifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.9872420745069393\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(prediction_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0105316\n",
      "Accuracy = 98.9468405215647\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(prediction_dt)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print('Accuracy =', accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-cross\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "grid = ParamGridBuilder().addGrid(dt.maxDepth,[25]).build()\n",
    "cs_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "crossval = CrossValidator(estimator = dt,\n",
    "                          estimatorParamMaps = grid,\n",
    "                          evaluator = cs_evaluator,\n",
    "                          numFolds =10 )\n",
    "cvModel = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9899699097291875\n"
     ]
    }
   ],
   "source": [
    "print(cs_evaluator.evaluate(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3.2 Random Forrest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20)\n",
    "model_rf = rf.fit(trainingData)\n",
    "prediction_rf = model_rf.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary classifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.9989685902118332\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.00702106\n",
      "Accuracy = 99.29789368104312\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracyrf = evaluator.evaluate(prediction_rf)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracyrf))\n",
    "print('Accuracy =', accuracyrf*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-cross\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "grid = ParamGridBuilder().addGrid(rf.maxDepth,[25,10]).addGrid(rf.numTrees,[5,10]).build()\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "crossval = CrossValidator(estimator = rf,\n",
    "                          estimatorParamMaps = grid,\n",
    "                          evaluator = rf_evaluator,\n",
    "                          numFolds =10 )\n",
    "rfModel = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfresult = rfModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9929789368104313\n"
     ]
    }
   ],
   "source": [
    "print(rf_evaluator.evaluate(rfresult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CityIndex': 0.031518063066468864, 'O3': 0.012312122060959631, 'CO': 0.011963262573339175, 'SO2': 0.006204718552057114, 'NO': 0.06276796663963156, 'NOx': 0.2085396878155751, 'Benzene': 0.0012991069427307762, 'PM25': 0.6011814049446115, 'NH3': 0.002251441441279128, 'NO2': 0.059622133961276226, 'Toluene': 0.0023400920020711603}\n"
     ]
    }
   ],
   "source": [
    "#importance evaluation for random forrest\n",
    "importance = model_rf.featureImportances\n",
    "column_list = finaldf.columns\n",
    "column_list.remove(\"ChangeStrategyOrNot\")\n",
    "importancesList = [float(col) for col in importance ]\n",
    "\n",
    "final = dict(zip(column_list, importancesList))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CityIndex': 0.02811704059072851, 'O3': 0.001971750491355737, 'CO': 0.005343342807943468, 'SO2': 0.0013499743426237593, 'NO': 0.0017874348623360741, 'NOx': 0.004290210558966963, 'Benzene': 0.0010300472088038417, 'PM25': 0.9527184489163569, 'NH3': 0.0, 'NO2': 0.0007010043504359482, 'Toluene': 0.0026907458704488654}\n"
     ]
    }
   ],
   "source": [
    "#importance evaluation for decision tree\n",
    "importance = model_dt.featureImportances\n",
    "column_list = finaldf.columns\n",
    "column_list.remove(\"ChangeStrategyOrNot\")\n",
    "importancesList = [float(col) for col in importance ]\n",
    "\n",
    "final = dict(zip(column_list, importancesList))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_dt.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3.3 Gradient Boosted Tree\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = gbt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1035, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1035, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:45619)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-19f61f414004>\", line 9, in <module>\n",
      "    gbtModel = crossval.fit(trainingData)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 64, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\", line 236, in _fit\n",
      "    model = est.fit(train, epm[j])\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\", line 62, in fit\n",
      "    return self.copy(params)._fit(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 236, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 233, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o6659.fit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o6659.fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-19f61f414004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                           \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbt_evaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           numFolds =10 )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgbtModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumModels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0;31m# TODO: duplicate evaluator to take extra params from input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \"\"\"\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n\u001b[1;32m    326\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o6659.fit"
     ]
    }
   ],
   "source": [
    "#10-cross GBT\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "gbdgrid = ParamGridBuilder().addGrid(gbt.maxDepth,[25,10]).build()\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "crossval = CrossValidator(estimator = gbt,\n",
    "                          estimatorParamMaps = gbdgrid,\n",
    "                          evaluator = gbt_evaluator,\n",
    "                          numFolds =10 )\n",
    "gbtModel = crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtresult = gbtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbt_evaluator.evaluate(gbtresult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#evaluate\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print('Accuracy',accuracy )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = model.featureImportances\n",
    "column_list = finaldf.columns\n",
    "column_list.remove(\"ChangeStrategyOrNot\")\n",
    "importancesList = [float(col) for col in importance ]\n",
    "\n",
    "final = dict(zip(column_list, importancesList))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
